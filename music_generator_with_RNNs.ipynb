{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsvlBQYCrE4I"
      },
      "source": [
        "### 1.   download all necessairy dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install livelossplot"
      ],
      "metadata": {
        "id": "ZMTNEnlqOP9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riVZCVK65QTH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from livelossplot import PlotLosses\n",
        "from keras.layers import SimpleRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajvp0No4qDm"
      },
      "source": [
        "### 2.   download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d4GwazAyjpJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# opening the file\n",
        "train_file = open('/content/drive/MyDrive/music-generator/train.json')\n",
        "\n",
        "json_data = json.load(train_file)\n",
        "train_list = []\n",
        "for item in json_data:\n",
        "  train_list.append(item[\"abc notation\"])\n",
        "\n",
        "train_text = \"\\n\\n\".join(train_list)\n",
        "print(train_text[:500])\n",
        "\n",
        "# closing the file\n",
        "train_file.close()"
      ],
      "metadata": {
        "id": "SEdeWVNyjnlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Test our data"
      ],
      "metadata": {
        "id": "N_oyYR5GoaTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7dFnP5q3Jve"
      },
      "outputs": [],
      "source": [
        "from music21 import converter\n",
        "song = converter.parse(train_list[random.randint(0,100)])\n",
        "song.show('midi')\n",
        "\n",
        "print(train_list[random.randint(0,100)])\n",
        "# song.write('midi', fp='output.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## 3. building the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, text_data, eost=None):\n",
        "        self.tokens = sorted(set(train_text))\n",
        "        self.stoi = {s:i for i, s in enumerate(self.tokens)}\n",
        "        self.vocab_size = len(self.tokens)\n",
        "        if eost:\n",
        "            self.stoi[\"%\"] = self.vocab_size\n",
        "            self.vocab_size +=1\n",
        "        self.itos = {i:s for s, i in self.stoi.items()}\n",
        "\n",
        "    def encode(self, songs_string):\n",
        "      enc = []\n",
        "      for s in list(songs_string):\n",
        "          enc.append(self.stoi[s])\n",
        "      return enc\n",
        "\n",
        "    def decode(self, songs_arr):\n",
        "      dec = []\n",
        "      for i in songs_arr:\n",
        "          dec.append(self.itos[i])\n",
        "      return \"\".join(dec)\n",
        "\n",
        "tokenizer = Tokenizer(train_text)\n",
        "print(f\"size of the vocabulary : {tokenizer.vocab_size}\")\n",
        "# print(tokenizer.itos.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc = tokenizer.encode(\"E2 EF E2 B2 |1 efe^d e2 e2\")\n",
        "print(enc)\n",
        "print(tokenizer.decode(enc))"
      ],
      "metadata": {
        "id": "FB6_zDsfzBY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. tokenize abc annotations"
      ],
      "metadata": {
        "id": "0d92cIerMey0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-LnKyu4dczc"
      },
      "outputs": [],
      "source": [
        "train_tokens = tokenizer.encode(train_text)\n",
        "train_tokens[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "## 5. let's now create batchs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF-N8F7BoDRi"
      },
      "outputs": [],
      "source": [
        "def get_batch(train_tokens, block_size, batch_size):\n",
        "  idx = np.random.choice(len(train_tokens)-block_size-1, batch_size)\n",
        "\n",
        "  x = np.reshape([train_tokens[i:i+block_size] for i in idx], [batch_size, block_size])\n",
        "  y = np.reshape([train_tokens[i+1:i+block_size+1] for i in idx], [batch_size, block_size])\n",
        "  return x, y\n",
        "\n",
        "get_batch(train_tokens, block_size=8, batch_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## 5. Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaOqndqBmJo"
      },
      "source": [
        "> let's define LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DsWzojvkbc7"
      },
      "outputs": [],
      "source": [
        "def RNNs_Builder(rnn_units):\n",
        "    return SimpleRNN(\n",
        "        rnn_units,\n",
        "        return_sequences=True,\n",
        "        activation='tanh',\n",
        "        use_bias=True,\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        recurrent_initializer='orthogonal',\n",
        "        bias_initializer='zeros',\n",
        "        stateful=True,\n",
        "    )\n",
        "\n",
        "rnn = RNNs_Builder(32)\n",
        "print(f\"RNN Units: {rnn.units}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbWU4dMJmMvq"
      },
      "source": [
        "> let's stack lstms together then add fcn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "outputs": [],
      "source": [
        "def Model_Builder(vocab_size, emb_size, lstm_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,\n",
        "                                emb_size,\n",
        "                                batch_input_shape=[batch_size, None]),\n",
        "      RNNs_Builder(lstm_units),\n",
        "      tf.keras.layers.Dense(units=vocab_size,\n",
        "                            activation='relu',\n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            bias_initializer='zeros')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwG1DD6rDrRM"
      },
      "outputs": [],
      "source": [
        "model = Model_Builder(tokenizer.vocab_size, emb_size=64, lstm_units=128, batch_size=16)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xeDn5nZD0LX"
      },
      "source": [
        "> check input, output dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_70kKAPrPU"
      },
      "outputs": [],
      "source": [
        "input, _ = get_batch(train_tokens, block_size=8, batch_size=16)\n",
        "output = model(input)\n",
        "print(f\"Input shape: [batch_size, sequence_length] <==> {input.shape}\")\n",
        "print(f\"output shape: [batch_size, sequence_length, vocab_size] <==> {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## 6. Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Seh7e6eRqd7"
      },
      "source": [
        "> Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQWUUhKotkAY"
      },
      "outputs": [],
      "source": [
        "chpt_dir = './content/model_checkpoints'\n",
        "chpt_prefix = os.path.join(chpt_dir, \"lstm_chpts\")\n",
        "\n",
        "num_steps = 2000\n",
        "batch_size = 64\n",
        "block_size = 200\n",
        "vocab_size = tokenizer.vocab_size\n",
        "lr = 5e-3\n",
        "emb_size = 256\n",
        "lstm_units = 1024\n",
        "beta1, beta2=0.9, 0.99\n",
        "eps=1e-06"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> loss functions (We have defined it separately because we want to experiment with the loss function as well.)"
      ],
      "metadata": {
        "id": "EpzOKZbhqoP5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HrXTACTdzY-"
      },
      "outputs": [],
      "source": [
        "def loss_function(y, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(y, logits, from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cu11p1MKYZd"
      },
      "source": [
        "> initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F31vzJ_u66cb"
      },
      "outputs": [],
      "source": [
        "model = Model_Builder(vocab_size=vocab_size,\n",
        "                        emb_size=emb_size,\n",
        "                        lstm_units=lstm_units,\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr,\n",
        "    beta_1=beta1,\n",
        "    beta_2=beta2,\n",
        "    epsilon=eps,\n",
        "    name='Adam',\n",
        ")\n",
        "\n",
        "# optimizer = tf.keras.optimizers.experimental.Adagrad(\n",
        "#     learning_rate=lr,\n",
        "#     initial_accumulator_value=0.1,\n",
        "#     epsilon=1e-07,\n",
        "#     ema_momentum=0.99,\n",
        "#     ema_overwrite_frequency=None,\n",
        "#     jit_compile=True,\n",
        "#     name='Adagrad',\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> one step of training"
      ],
      "metadata": {
        "id": "z2I-gs27plmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_iter(xb, yb):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(xb)\n",
        "    loss = loss_function(yb, logits)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "vpXzZM4FpmBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liveloss = PlotLosses()\n",
        "logs = {}\n",
        "\n",
        "# clear previous tqdm instances\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear()\n",
        "\n",
        "# start training\n",
        "for iter in tqdm(range(num_steps)):\n",
        "  xb, yb = get_batch(train_tokens, block_size=block_size, batch_size=batch_size)\n",
        "\n",
        "  loss = train_iter(xb, yb)\n",
        "\n",
        "  logs[\"train\"] = loss.numpy().mean()\n",
        "  liveloss.update(logs)\n",
        "  liveloss.draw()\n",
        "\n",
        "  if iter % 10 == 0:\n",
        "    model.save_weights(chpt_prefix)"
      ],
      "metadata": {
        "id": "kJvJ2H_EO0cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## 7. let's load our model and re-build it (with batch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LycQ-ot_jjyu"
      },
      "outputs": [],
      "source": [
        "infer_model = Model_Builder(vocab_size, emb_size, lstm_units, batch_size=1)\n",
        "\n",
        "# Restore the model weights for the last checkpoint after training\n",
        "infer_model.load_weights(tf.train.latest_checkpoint(chpt_dir))\n",
        "infer_model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "infer_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "## 8. Convert ABC annotations to our music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "outputs": [],
      "source": [
        "def generate_ABC(model, start, length=1000):\n",
        "  input_eval = tf.expand_dims(tokenizer.encode(start), 0)\n",
        "\n",
        "  generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(length)):\n",
        "      preds = model(input_eval)\n",
        "      preds = tf.squeeze(preds, 0)\n",
        "      id = tf.random.categorical(preds, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([id], 0)\n",
        "      generated.append(tokenizer.decode([id]))\n",
        "  return (start + ''.join(generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktovv0RFhrkn"
      },
      "outputs": [],
      "source": [
        "ABC = generate_ABC(infer_model, start=\"M:4/4\\nK:A\\nA\", length=500)\n",
        "print(ABC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "## 9. Convert ABC annotation to audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrOtG64bfLto"
      },
      "outputs": [],
      "source": [
        "from music21 import converter\n",
        "song = converter.parse(ABC)\n",
        "song.show('midi')\n",
        "\n",
        "# song.write('midi', fp='output.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Congratulations! You can now relish your very own melodies.:***\n",
        "\n",
        "<img width=\"100%\" src=\"https://github-production-user-asset-6210df.s3.amazonaws.com/89405673/247540874-82a528db-da22-4d14-a3c6-5360655384da.gif\"/>"
      ],
      "metadata": {
        "id": "addhLMEI0d2i"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "collapsed_sections": [
        "rsvlBQYCrE4I",
        "rNnrKn_lL-IJ",
        "0d92cIerMey0",
        "hgsVvVxnymwf"
      ],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}